{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction\n",
    "The fist step in MoSeq after data collection is to take the raw data and transform it into a representation that minmizes sources of variability that are not attributed to the animal's pose (e.g. it's location) and is less computationally expensive (i.e. less pixels). We accomplish this in the following steps:\n",
    "\n",
    "1. Perform background subtraction such that the only positive pixels are those that are dynamic across time\n",
    "2. Detect where the rat is in the frame using a segmentation network\n",
    "3. Zero out all the pixels that are not attributed to the rat\n",
    "4. Crop the frame around the rat\n",
    "5. Rotate the rat so that it is always facing right \n",
    "\n",
    "This handles various sources of noise that might corrupt the data and impact your experiment. For instance, if you didn't crop the data, there would be a large amount of variance attributed to where the animal is in the arena, and MoSeq would learn syllables that are specific to the location of the animal. Next, if we didn't make sure the animal is always facing right MoSeq would learn syllables that are due to the animal flipping it's orientation due to our own error in orienting it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to perform background extraction: 1.) take the median of each pixel across time or 2.) estimating a plane. Since we have depth data, we can accomplish the second by just estimating the plane that exists on the floor of the bucket. For azure data, only use the plane option. \n",
    "\n",
    "Once we subtract the background from the raw video, we get the distance of each pixel on the rat to the bucket floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'ratmoseq-extract (Python 3.10.16)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n ratmoseq-extract ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# TODO: include images of rat data, median background, and plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rat detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've succesfully subtracted the background, we then want to zero out any noise that doesn't have to do with the animal. We accomplish this through using Meta's Segment Anything 2 (sam2) model and keypoints detected using deeplabcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'ratmoseq-extract (Python 3.10.16)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n ratmoseq-extract ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# TODO: include code block that segments the rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping and rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Now that we have the segmentation accomplished, let's go ahead and crop the frame to the center of the rat, and then rotate the rat so that it is always facing the same direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include code block that shows the cropped and rotated rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running it all using ratmoseq\n",
    "Those are all the steps mentioned above, we can automate this by using the ratmoseq command line interface using the command below. After running it, you should find a `proc` directory in the same folder that has the `depth.avi` file you are pointing to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include ratmoseq command"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ratmoseq-extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
